{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from nltk import PorterStemmer\n",
    "from pyspark import SparkContext\n",
    "import re\n",
    "import operator\n",
    "from operator import add\n",
    "\n",
    "#Loading the Data\n",
    "start_time = time.time()\n",
    "path_1 = \"C:\\\\Users\\\\nirav\\\\Downloads\\\\WordCountData.txt\"\n",
    "sc = SparkContext()\n",
    "textfile = sc.textFile(path_1)\n",
    "singleListData = (textfile.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Stoping Process with Response Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 1_STOPPING_RESPONSE TIME: 0.10533380508422852 SECONDS\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "words = word_tokenize(str(singleListData))\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "\n",
    "print(\"PART 1_STOPPING_RESPONSE TIME: %s SECONDS\" % (time.time() - time1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cleaning the data, removing unnecessary characters with Response Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 2_CLEANING DATA_RESPONSE TIME: 0.02356410026550293 SECONDS\n"
     ]
    }
   ],
   "source": [
    "time2 = time.time()\n",
    "wordsToRemove = [\",\",\"'nan\", \"]\", \"'\", \".\", \";\", \"''\", \"[\", \"``\", \"'I\", \"'of\", \"'is\", \"'are\", \"'in\", \"'In\", \"'by\", \"'the\", \"'and\",\"!\", \"'d\",\"'If\", \"'so\",\"'me\", \"'my\", \"(\", \")\", \":\",\"'was\", \"'And\", \"'a\", \"'to\", \"'That\", \"'that\", \"'as\", \"'As\" \"'us\"]\n",
    "for i in range(0, len(wordsToRemove)):\n",
    "    wordsFiltered = [x for x in wordsFiltered if x != wordsToRemove[i]]\n",
    "print(\"PART 2_CLEANING DATA_RESPONSE TIME: %s SECONDS\" % (time.time() - time2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Stemming Process with Response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3_STEMMING_RESPONSE TIME: 0.0015034675598144531 SECONDS\n"
     ]
    }
   ],
   "source": [
    "time3 = time.time()\n",
    "stemmedWords = PorterStemmer().stem(str(wordsFiltered))\n",
    "print(\"PART 3_STEMMING_RESPONSE TIME: %s SECONDS\" % (time.time() - time3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: number of lines, characters and occurance of characters with response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF LINES IN FILE ARE: 1449\n",
      "NUMBER OF CHARACTERS IN FILE ARE: 59259\n",
      "PART 4_RESPONSE TIME: 4.048681735992432 SECONDS\n"
     ]
    }
   ],
   "source": [
    "time4 = time.time()\n",
    "stemmedWords = stemmedWords.split() #converting string to list\n",
    "text2 = sc.parallelize(stemmedWords)\n",
    "print ('NUMBER OF LINES IN FILE ARE: %s' % textfile.count())\n",
    "chars = textfile.map(lambda s: len(s)).reduce(add)\n",
    "print ('NUMBER OF CHARACTERS IN FILE ARE: %s' % chars)\n",
    "\n",
    "words = text2.flatMap(lambda line: re.split('\\W+', line.lower().strip())) #use of flatmap\n",
    "words = words.filter(lambda x: len(x) > 3) \n",
    "words = words.map(lambda w : (w,1)) #use of mapping \n",
    "words = words.reduceByKey(add) #reduce by key\n",
    "print(\"PART 4_RESPONSE TIME: %s SECONDS\" % (time.time() - time4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing most 50 occurance words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would', 18), ('like', 15), ('spirit', 12), ('when', 12), ('ever', 11), ('where', 10), ('behold', 9), ('mighty', 7), ('sphere', 7), ('free', 7), ('matter', 6), ('work', 6), ('beyond', 5), ('hast', 5), ('bosom', 4), ('guide', 4), ('stood', 3), ('broad', 3), ('plac', 3), ('store', 2), ('brows', 2), ('harmony', 2), ('dull', 2), ('cord', 2), ('dart', 2), ('bend', 2), ('returns', 2), ('glorious', 2), ('space', 2), ('bespake', 2), ('sheds', 1), ('nathless', 1), ('benign', 1), ('remaining', 1), ('diver', 1), ('herb', 1), ('serve', 1), ('rain', 1), ('imagination', 1), ('entangled', 1), ('admiration', 1), ('binds', 1), ('orders', 1), ('sometimes', 1), ('creature', 1), ('advent', 1), ('reveal', 1), ('fearless', 1), ('plough', 1), ('loosen', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sorted(words.take(50),key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The time consumed for whole program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHOLE PROGRAM_RESPONSE TIME: 14.204959630966187 SECONDS\n"
     ]
    }
   ],
   "source": [
    "print(\"WHOLE PROGRAM_RESPONSE TIME: %s SECONDS\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
